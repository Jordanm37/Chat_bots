{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\deeplake\\util\\check_latest_version.py:32: UserWarning: A newer version of deeplake (3.6.10) is available. It's recommended that you update to the latest version using `pip install -U deeplake`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain.document_loaders import UnstructuredExcelLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "# load the API key from the .env file\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# user_input = input(\"User: \")\n",
    "# load the documents from the docs directory\n",
    "loader = PyPDFDirectoryLoader(\"docs/\")\n",
    "docs = loader.load()\n",
    "\n",
    "#split the documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(docs)\n",
    "\n",
    "# create the vector store directory\n",
    "persist_directory = 'db'\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "# create the vector store\n",
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)\n",
    "\n",
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load vector db from disk\n",
    "persist_directory = 'db'\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom prompts\n",
    "CONDENSE_PROMPT = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "QA_PROMPT = \"\"\"You will act as an AI Assistant that I am having a conversation with. You have access to a clients training records and will be asked questions relating to their performance. You will ask follow-up questions to clarify the last response and provide more accurate and personalized answers. If the answer is not included in your knowledge base, you will say 'Hmm, I am not sure.' and stop after that. Your goal is to provide the best possible guidance and support to help me with my queries and problems. You think things through step by step every time and show your working. You break down problems into simple steps before solving and always double check your answers. \n",
    "\n",
    "{summaries}\n",
    "\n",
    "Question: {question}\n",
    "Helpful answer in markdown or latex where equations are included:\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "# Create PromptTemplate instances\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"], \n",
    "    template=CONDENSE_PROMPT\n",
    ")\n",
    "\n",
    "QA_PROMPT_TEMPLATE = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"], \n",
    "    template=QA_PROMPT\n",
    ")\n",
    "\n",
    "# initialise llm instances and chains\n",
    "gpt3 = ChatOpenAI(temperature=0, model_name = 'gpt-3.5-turbo')\n",
    "gpt4 = ChatOpenAI(temperature=0, model_name = 'gpt-4')\n",
    "question_generator = LLMChain(llm=gpt3, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_with_sources_chain(gpt4, chain_type=\"stuff\", prompt=QA_PROMPT_TEMPLATE)\n",
    "\n",
    "# declare main retrieval chain\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents = True\n",
    ")\n",
    "\n",
    "def chat_bot_response(message, chat_history):\n",
    "    # chat_history.append(message)\n",
    "    result = chain({\"question\": message, \"chat_history\": chat_history})\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "message = \"What is the best bench press result?\"\n",
    "res = chat_bot_response(message, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The client has reported discomfort in the right shoulder, specifically in the pec minor region. This discomfort seems to restrict certain movements. The client also mentioned that they are unable to perform the decline DB press without damaging the DBs, possibly due to difficulty in getting up. Additionally, they have requested to remove pull-ups from their routine, which could suggest difficulty or discomfort in performing this exercise.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = []\n",
    "message = \"What injuries or difficulties training does the client have?\"\n",
    "res = chat_bot_response(message, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What injuries or difficulties training does the client have?',\n",
       " 'chat_history': [],\n",
       " 'answer': 'The client has reported discomfort in the right shoulder, specifically in the pec minor region. This discomfort seems to restrict certain movements. The client also mentioned that they are unable to perform the decline DB press without damaging the DBs, possibly due to difficulty in getting up. Additionally, they have requested to remove pull-ups from their routine, which could suggest difficulty or discomfort in performing this exercise.',\n",
       " 'source_documents': [Document(page_content=\"000000\\nCant do decline DB press cause cant get up without hurting the DB's\\nTake pull ups out\\nDiscomfort in right shoulder (pec minor region) restriction \\nGive floor press option\", metadata={'source': 'docs\\\\test.pdf', 'page': 60}),\n",
       "  Document(page_content='000000\\nWants arms to grow - inparticular biceps', metadata={'source': 'docs\\\\test.pdf', 'page': 14}),\n",
       "  Document(page_content='Week 6 Cross Trainer or Treadmill or Bike 15 mins 120-140 bpm\\nDAY 5 WHOLE BODY C DAY/DATE; DAY/DATE; 25/3 DAY/DATE;31/3 DAY/DATE;5/4 DAY/DATE;15/4 DAY/DATE;\\nOrder Exercise Reps Sets Tempo Rest Week 1  (3 sets ALL) Week 2  (3 sets ALL) Week 3  (3 sets ALL) Week 4  (3 sets ALL) Week 5  (3 sets ALL) Week 6  (2 sets ALL)\\nM1 Stick Dislocates 10 1 Controlled\\nM2 Rolling Plank Front, Side, Front, Side 30s 15s 15s 15s 1 Controlled\\nM3 Side lying Clams 25 each side 1 Controlled p\\nM4 Single leg balance with iron edge ball throws 20 each side 2 Controlled 20,20,20 20,20 20, 20 20,20 20,20\\nA1 - PracticeGoblet squat without heel elevation 10s down 1s pause @ \\nbottom and 10s up (focus on brace)1 2 101100 30 10 10, 10 10, 10 10,10 10,10\\nA2 - PracticeBB Squats without heel elevation 5s down w/2s pause @ \\nbottom - Potentially front squats3 2 5210 90 45*3, 3 50*3,3 55* 50*3 55*3,3\\nBBB Squat - Full squat - Slight heel elevation - green plate -', metadata={'source': 'docs\\\\test.pdf', 'page': 3}),\n",
       "  Document(page_content='000000\\nUpper Pecs \\nDeadlifts from ground \\nTrap 3 raises \\nRear delt emphasis\\nUpper pec (give flys)\\nHanging knee raises \\nGIGANTIC BICEPS (a personal goal)\\n147/87 Blood pressure.', metadata={'source': 'docs\\\\test.pdf', 'page': 59})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
