{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  TODO Add google translate API\n",
    "#  TODO code document translate from pdf with file upload\n",
    "#  TODO add streaming to responses\n",
    "#  TODO format key word output for translator to use dictionary\n",
    "#  TODO add transcription grammar correction for students\n",
    "#  TODO add google translate api for key word translation\n",
    "#  TODO make basic backend and front end site to frame connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "message = b'hell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import whisper\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "import logging\n",
    "\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "openai.api_key = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a logger\n",
    "logging.basicConfig(filename='example2.log',level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Chatgpt chat completition with input arguments for system message and user message\n",
    "\n",
    "def chatbot_completition(system_message, user_message):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model = 'gpt-4',\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system_message},\n",
    "            {\"role\": \"user\", \"content\": user_message},\n",
    "        ],\n",
    "    )\n",
    "    \n",
    "    prompt, reply = response['usage']['prompt_tokens'], response['usage']['completion_tokens']\n",
    "    cost = (0.03/1000)*prompt + (0.06/1000)*reply\n",
    "    ## calculate api costs and log it\n",
    "    logger.info(f\"Prompt tokens: {prompt}, Completion tokens: {reply}, Cost: {cost}\")\n",
    "\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translation chain\n",
    "class Translation:\n",
    "    def __init__(self, source_language, target_language):\n",
    "        self.source_language = source_language\n",
    "        self.target_language = target_language\n",
    "        \n",
    "    def translate(self, text):\n",
    "        logger.info(\"Starting translation...\")\n",
    "        \n",
    "        logger.info(\"Extracting context...\")\n",
    "        context = self.extract_context(text)\n",
    "        logger.info(f\"Context extracted: {context}\")\n",
    "        \n",
    "        logger.info(\"Extracting key words...\")\n",
    "        key_words = self.extract_key_words(text)\n",
    "        logger.info(f\"Key words extracted: {key_words}\")\n",
    "        \n",
    "        SYSTEM = f\"\"\"You are an expert {self.target_language} translator. Your role is to carefully examine the given text, which may be written in {self.source_language}, and translate it accurately into {self.target_language}. Your translation work should account for not only literal translation but also cultural and contextual nuances. You'll be given text that has to be translated into {self.target_language}, the context of the text and key words with possible translations. Your task is to ensure the translated text preserves the original message while being grammatically correct and contextually appropriate in {self.target_language}. If the text is not in {self.source_language} you will say \"Please enter text in {self.source_language} to translate\" Respond using markdown.\"\"\"\n",
    "        \n",
    "        example_en_to_gr = f\"\"\"                    \n",
    "                    \"Given this text to translate: \"It's a beautiful sunny day at the beach.\"\n",
    "                    Translate it from English to Greek:\n",
    "                    Given the context: \"This sentence is describing a pleasant weather condition at a seaside location.\" and key words: \"beautiful (όμορφος), sunny (ηλιόλουστος), day (μέρα), beach (παραλία)\"\n",
    "                    The translation is: \"Είναι μια όμορφη ηλιόλουστη μέρα στην παραλία.\" \n",
    "                    \"\"\"\n",
    "        example_gr_to_en = f\"\"\"\n",
    "                    \"Given this text to translate: \"Είναι μια όμορφη ηλιόλουστη μέρα στην παραλία.\"\n",
    "                    Translate it from Greek to English:\n",
    "                    Given the context: \"This sentence is describing a pleasant weather condition at a seaside location.\" and key words: \"όμορφη (beautiful), ηλιόλουστη (sunny), μέρα (day), παραλία (beach)\"\n",
    "                    The translation is: \"It's a beautiful sunny day at the beach.\" \" \n",
    "                    \"\"\"\n",
    "                    \n",
    "        if self.source_language == \"English\":\n",
    "            example = example_en_to_gr\n",
    "        else:\n",
    "            example = example_gr_to_en\n",
    "                \n",
    "        PROMPT = f\"\"\"\n",
    "                    Translate from {self.source_language} to {self.target_language}:\n",
    "                    \n",
    "                    Example:\n",
    "                    {example}\n",
    "                    \n",
    "                    Now, given this text to translate: \"{text}\"\n",
    "       \n",
    "                    Given the context: \"{context}\" and key words: \"{key_words}\"\n",
    "                    \n",
    "                    The translation is:\n",
    "                    \"\"\"\n",
    "        logger.info(\"Translating text...\")\n",
    "        translation = chatbot_completition(SYSTEM, PROMPT)\n",
    "        logger.info(f\"Translation completed: {translation}\")\n",
    "        \n",
    "        return translation, key_words\n",
    "        \n",
    "    \n",
    "    def extract_context(self, text):\n",
    "        '''Extracts context from text using chatgpt api call'''\n",
    "        \n",
    "        SYSTEM = \"You are a sophisticated AI model capable of understanding and interpreting English text. Your task is to identify and describe the overall context or main topic of the following text.\"\n",
    "        PROMPT = f\"Please identify the context of this text: \\\"{text}\\\"\"\n",
    "        context = chatbot_completition(SYSTEM, PROMPT)\n",
    "        \n",
    "        return context\n",
    "\n",
    "    def extract_key_words(self, text):\n",
    "        '''Extracts key words from text using chatgpt api call'''\n",
    "        \n",
    "        if self.source_language == \"English\":\n",
    "            SYSTEM = \"\"\"You are a sophisticated AI model trained to identify key words and phrases in English text. Your task is to extract the most important words or phrases that capture the main points of the following text.\n",
    "            Example:\n",
    "            Text:\"It's a beautiful sunny day at the beach.\"\n",
    "            key words: \"beautiful (όμορφος), sunny (ηλιόλουστος), day (μέρα), beach (παραλία)\"\n",
    "            \"\"\"\n",
    "        else:\n",
    "            SYSTEM = \"\"\"You are a sophisticated AI model trained to identify key words and phrases in Greek text. Your task is to extract the most important words or phrases that capture the main points of the following text.\n",
    "            Example:\n",
    "            Text:\"Είναι μια όμορφη ηλιόλουστη μέρα στην παραλία.\"\n",
    "            Key words: \"όμορφη (beautiful), ηλιόλουστη (sunny), μέρα (day), παραλία (beach)\"\n",
    "            \"\"\"\n",
    "        PROMPT = f\"\"\"Please extract the key words from this text: \\\"{text}\\ and their possible translations in {self.target_language}.\n",
    "        \"\"\"\n",
    "        key_words = chatbot_completition(SYSTEM, PROMPT)\n",
    "        return key_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transcription:\n",
    "    def __init__(self, source_language, target_language):\n",
    "        self.source_language = source_language\n",
    "        self.target_language = target_language\n",
    "        self.model = whisper.load_model(\"large\")\n",
    "        self.translate = Translation(source_language, target_language)\n",
    "\n",
    "    def transcribe(self, audio_file):\n",
    "        '''Transcribes the audio file and proofreads the transcription'''\n",
    "\n",
    "        ### Size (in bytes) = (Sample Rate) * (Bit Depth/8) * (Number of Channels) * (Duration in seconds)\n",
    "        ### Size = 44,100 * (16/8) * 1 * 60 = 5,292,000 bytes, which is approximately 5 MB.\n",
    "\n",
    "        # Calculate the size of the audio file\n",
    "        audio_file_size = os.path.getsize(audio_file)\n",
    "        audio_length = audio_file_size / ( 44100 * (16/8) * 1 )\n",
    "        logger.info(f\"Audio file size: {audio_file_size} bytes and {audio_length} seconds\")\n",
    "\n",
    "        # Transcribe the audio\n",
    "        logger.info(\"Starting transcription...\")\n",
    "        transcription = self.transcribe_audio(audio_file)\n",
    "        logger.info(f\"Transcription completed: {transcription}\")\n",
    "\n",
    "        # Proofread the transcription\n",
    "        logger.info(\"Proofreading transcription...\")\n",
    "        proofread_transcription = self.proofread_transcription(transcription)\n",
    "        logger.info(f\"Proofread transcription: {proofread_transcription}\")\n",
    "\n",
    "        # Translate the transcription\n",
    "        translation,key_words = self.translate.translate(proofread_transcription)\n",
    "        \n",
    "        return proofread_transcription, translation, key_words\n",
    "\n",
    "    def transcribe_audio(self, audio_path):\n",
    "        '''Transcribes an audio file using the whisper model'''\n",
    "        \n",
    "        # Check if file size is less than 25 MB\n",
    "        file_size = os.path.getsize(audio_path) / (1024 * 1024) # size in MB\n",
    "        if file_size > 25:\n",
    "            raise ValueError(f\"The file size is {file_size:.2f} MB which exceeds the 25 MB limit.\")\n",
    "\n",
    "        # Check if file extension is supported\n",
    "        supported_file_types = ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm']\n",
    "        file_extension = os.path.splitext(audio_path)[1][1:]\n",
    "        if file_extension not in supported_file_types:\n",
    "            raise ValueError(f\"The file type '{file_extension}' is not supported. Please use one of the following: {', '.join(supported_file_types)}.\")\n",
    "\n",
    "        # If checks pass, transcribe the audio\n",
    "        audio_file = open(audio_path, \"rb\")\n",
    "        transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "\n",
    "        # Always close the file you opened\n",
    "        audio_file.close()\n",
    "\n",
    "        return transcript\n",
    "        \n",
    "        # result = self.model.transcribe(audio_file)        \n",
    "        # return result[\"text\"]\n",
    "\n",
    "    def proofread_transcription(self, transcription):\n",
    "        '''Improves the transcription quality using GPT-4'''\n",
    "        \n",
    "        SYSTEM = \"\"\"You are an expert {self.source_langauge} transcription agent. In particular, an advanced language model trained to proofread and correct text based on grammar, syntax, and coherence in context. Your role is to carefully examine the given text in {self.source_langauge}, identify semantic errors resulting from transcription, and then correct these errors. Use your knowledge of {self.source_language} language and syntax to ensure the accuracy and coherence of the transcriptions. Your task is crucial for the quality and usefulness of the transcriptions. You will be given {self.source_langauge} text that has been transcribed but may contain errors. Your job is to fix these errors to the best of your ability. Respond using markdown.\n",
    "        \n",
    "        You will work through proofreading and correcting the transcription in the following way step by step:\n",
    "        \n",
    "        Identify the context: [context]\n",
    "        Identify key words: [key words]\n",
    "        Correct the transcription: [transcription]\n",
    "        \n",
    "        You will not add any additional detail to the transcription. You will only correct the transcription. You will only return the transcription. You will not return the context or key words.\n",
    "        \n",
    "        Write the transcription here:\n",
    "               \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        PROMPT = f\"Please proofread and correct this transcription: \\\"{transcription}\\\"\"\n",
    "        proofread_transcription = chatbot_completition(SYSTEM, PROMPT)\n",
    "        return proofread_transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from docx import Document\n",
    "\n",
    "class DocumentTranslation(Translation):\n",
    "    '''Class to translate pdf documents into English from Greek'''\n",
    "    # Inherits from the Translation class\n",
    "    def __init__(self, source_language, target_language):\n",
    "        super().__init__(source_language, target_language)\n",
    "\n",
    "    def translate_document(self, file):\n",
    "        '''Function to translate a given document from Greek to English and extract key words'''\n",
    "        \n",
    "        logger.info(\"Starting document translation...\")\n",
    "        \n",
    "        document_type = os.path.splitext(file.name)[1][1:]\n",
    "        logger.info(f\"Document type: {document_type}\")\n",
    "        \n",
    "        text = self.open_pdf(file.name) if 'pdf' in document_type else self.open_word(file.name)\n",
    "        logger.info(f\"Document text: {text}\")\n",
    "        \n",
    "        translation, key_words = super().translate(text)\n",
    "        \n",
    "        return translation, key_words\n",
    "        \n",
    "    def open_pdf(self, pdf_path):\n",
    "        '''Opens a pdf file and extracts the text'''\n",
    "        \n",
    "        pdf = PdfReader(pdf_path)\n",
    "        text = \"\"\n",
    "        for page in range(len(pdf.pages)):\n",
    "            text += pdf.pages[page].extract_text()\n",
    "        \n",
    "        return text\n",
    "           \n",
    "    def open_word(self, word_path):\n",
    "        '''Opens a word file and extracts the text'''\n",
    "        \n",
    "        document = Document(word_path)\n",
    "        text = \"\"\n",
    "        for para in document.paragraphs:\n",
    "            text += para.text\n",
    "        \n",
    "        return text\n",
    "    \n",
    "    # def chunk_text(self, text):\n",
    "    #     '''Chunks the text into smaller pieces'''\n",
    "    #     pass\n",
    "    \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m file_2 \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mnew3_1.docx\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      6\u001b[0m translated_pdf,_ \u001b[39m=\u001b[39m document_translator\u001b[39m.\u001b[39mtranslate_document(file)\n\u001b[1;32m----> 7\u001b[0m translated_doc,_ \u001b[39m=\u001b[39m document_translator\u001b[39m.\u001b[39;49mtranslate_document(file_2)\n",
      "Cell \u001b[1;32mIn[54], line 21\u001b[0m, in \u001b[0;36mDocumentTranslation.translate_document\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m     18\u001b[0m text \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen_pdf(file) \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mpdf\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m document_type \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mopen_word(file)\n\u001b[0;32m     19\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDocument text: \u001b[39m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 21\u001b[0m translation, key_words \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtranslate(text)\n\u001b[0;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m translation, key_words\n",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m, in \u001b[0;36mTranslation.translate\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     12\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mContext extracted: \u001b[39m\u001b[39m{\u001b[39;00mcontext\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mExtracting key words...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m key_words \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_key_words(text)\n\u001b[0;32m     16\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey words extracted: \u001b[39m\u001b[39m{\u001b[39;00mkey_words\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m SYSTEM \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mYou are an expert \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_language\u001b[39m}\u001b[39;00m\u001b[39m translator. Your role is to carefully examine the given text, which may be written in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_language\u001b[39m}\u001b[39;00m\u001b[39m, and translate it accurately into \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_language\u001b[39m}\u001b[39;00m\u001b[39m. Your translation work should account for not only literal translation but also cultural and contextual nuances. You\u001b[39m\u001b[39m'\u001b[39m\u001b[39mll be given text that has to be translated into \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_language\u001b[39m}\u001b[39;00m\u001b[39m, the context of the text and key words with possible translations. Your task is to ensure the translated text preserves the original message while being grammatically correct and contextually appropriate in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_language\u001b[39m}\u001b[39;00m\u001b[39m. If the text is not in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_language\u001b[39m}\u001b[39;00m\u001b[39m you will say \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mPlease enter text in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msource_language\u001b[39m}\u001b[39;00m\u001b[39m to translate\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m Respond using markdown.\u001b[39m\u001b[39m\"\"\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[4], line 83\u001b[0m, in \u001b[0;36mTranslation.extract_key_words\u001b[1;34m(self, text)\u001b[0m\n\u001b[0;32m     76\u001b[0m     SYSTEM \u001b[39m=\u001b[39m \u001b[39m\"\"\"\u001b[39m\u001b[39mYou are a sophisticated AI model trained to identify key words and phrases in Greek text. Your task is to extract the most important words or phrases that capture the main points of the following text.\u001b[39m\n\u001b[0;32m     77\u001b[0m \u001b[39m    Example:\u001b[39m\n\u001b[0;32m     78\u001b[0m \u001b[39m    Text:\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mΕίναι μια όμορφη ηλιόλουστη μέρα στην παραλία.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     79\u001b[0m \u001b[39m    Key words: \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mόμορφη (beautiful), ηλιόλουστη (sunny), μέρα (day), παραλία (beach)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     80\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[0;32m     81\u001b[0m PROMPT \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\u001b[39mPlease extract the key words from this text: \u001b[39m\u001b[39m\\\"\u001b[39;00m\u001b[39m{\u001b[39;00mtext\u001b[39m}\u001b[39;00m\u001b[39m\\\u001b[39m\u001b[39m and their possible translations in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_language\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\n\u001b[0;32m     82\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m---> 83\u001b[0m key_words \u001b[39m=\u001b[39m chatbot_completition(SYSTEM, PROMPT)\n\u001b[0;32m     84\u001b[0m \u001b[39mreturn\u001b[39;00m key_words\n",
      "Cell \u001b[1;32mIn[3], line 4\u001b[0m, in \u001b[0;36mchatbot_completition\u001b[1;34m(system_message, user_message)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mchatbot_completition\u001b[39m(system_message, user_message):\n\u001b[1;32m----> 4\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m      5\u001b[0m         model \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mgpt-4\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[0;32m      6\u001b[0m         messages\u001b[39m=\u001b[39;49m[\n\u001b[0;32m      7\u001b[0m             {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: system_message},\n\u001b[0;32m      8\u001b[0m             {\u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39muser\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: user_message},\n\u001b[0;32m      9\u001b[0m         ],\n\u001b[0;32m     10\u001b[0m     )\n\u001b[0;32m     12\u001b[0m     prompt, reply \u001b[39m=\u001b[39m response[\u001b[39m'\u001b[39m\u001b[39musage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mprompt_tokens\u001b[39m\u001b[39m'\u001b[39m], response[\u001b[39m'\u001b[39m\u001b[39musage\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mcompletion_tokens\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m     13\u001b[0m     cost \u001b[39m=\u001b[39m (\u001b[39m0.03\u001b[39m\u001b[39m/\u001b[39m\u001b[39m1000\u001b[39m)\u001b[39m*\u001b[39mprompt \u001b[39m+\u001b[39m (\u001b[39m0.06\u001b[39m\u001b[39m/\u001b[39m\u001b[39m1000\u001b[39m)\u001b[39m*\u001b[39mreply\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[0;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\openai\\api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    594\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    597\u001b[0m         method,\n\u001b[0;32m    598\u001b[0m         abs_url,\n\u001b[0;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(prep, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39;49msend(request, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:714\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    711\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_proxy(conn)\n\u001b[0;32m    713\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 714\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    715\u001b[0m     conn,\n\u001b[0;32m    716\u001b[0m     method,\n\u001b[0;32m    717\u001b[0m     url,\n\u001b[0;32m    718\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    719\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    720\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    721\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    722\u001b[0m )\n\u001b[0;32m    724\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    725\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    726\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    727\u001b[0m \u001b[39m# mess.\u001b[39;00m\n\u001b[0;32m    728\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:466\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    461\u001b[0m             httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39mgetresponse()\n\u001b[0;32m    462\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 466\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    467\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    468\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\urllib3\\connectionpool.py:461\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[0;32m    459\u001b[0m     \u001b[39m# Python 3\u001b[39;00m\n\u001b[0;32m    460\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 461\u001b[0m         httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    462\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    463\u001b[0m         \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    464\u001b[0m         \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    465\u001b[0m         \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[0;32m    466\u001b[0m         six\u001b[39m.\u001b[39mraise_from(e, \u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1373\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    316\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    320\u001b[0m         \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\http\\client.py:279\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 279\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfp\u001b[39m.\u001b[39mreadline(_MAXLINE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    280\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    281\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\socket.py:705\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    703\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    704\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 705\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    706\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    707\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\ssl.py:1278\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1274\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1275\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1276\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1277\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1278\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1279\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1280\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\ssl.py:1134\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1132\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1133\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1134\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1135\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1136\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "document_translator = DocumentTranslation(\"Greek\", \"English\")\n",
    "\n",
    "file = \"new3_1.pdf\"\n",
    "file_2 = \"new3_1.docx\"\n",
    "\n",
    "translated_pdf,_ = document_translator.translate_document(file)\n",
    "translated_doc,_ = document_translator.translate_document(file_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The Thessaloniki Metro \n",
      "The construction of Thessaloniki's underground railway, that is, the Metro, has been under discussion since 1918. After many attempts, Thessaloniki's Metro started to become a reality, and it is estimated to be ready by 2023. The final cost of building the Metro would be much higher than initially calculated. There were many delays due mainly to significant archaeological findings during the Metro's construction. A whole ancient city was discovered under Thessaloniki! The Metro will culturally transform the city. It will connect the present with the past, providing the residents an opportunity to take pride in their city's history. \n",
      "\n",
      "Thessalonians, for many years, have suffered greatly from the Metro construction works because they have hampered their daily mobility, and business owners have lost incomes because people's access to the shops has been difficult. However, the Metro will provide a solution to the city's significant traffic problem. Distances will be covered faster, and residents will be able to move around more easily. \n",
      "\n",
      "Thessaloniki Metro Venizelou Station \n",
      "Source (image): Ministry of Infrastructure and Transport, Thessaloniki Metro, Venizelou Station... \n",
      "25 May 2020, from newsittv, <www.youtube.com/watch?v=-IvQKSEiBAY>\"\n",
      "\"The Thessaloniki Metro: The construction of Thessaloniki's underground railway, that is, the metro, has been discussed since 1918. After many efforts, the Thessaloniki Metro began becoming a reality, and it is estimated to be completed in 2023. However, the final cost of the metro construction will be much higher than initially estimated. There have been many delays, mainly due to significant archaeological finds discovered during the metro works. An entire ancient city was uncovered beneath Thessaloniki! The metro will bring about a cultural change in the city. It will connect the present with the past and give residents the opportunity to feel proud of their city's history. But Thessalonikians have been greatly inconvenienced by the metro construction for many years because they cannot move around freely, and business owners have lost income because people's access to shops has become difficult. However, the metro will provide a solution to the city's major traffic problem. Distances will be covered faster and residents will be able to move around more easily. Thessaloniki Metro Venizelos Station Source (image): Ministry of Infrastructure and Transport, Thessaloniki Metro, Venizelos Station... 25 May 2020, from newsittv, <www.youtube.com/watch?v=-IvQKSEiBAY>\"\n"
     ]
    }
   ],
   "source": [
    "print(translated_pdf)\n",
    "print(translated_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\gradio\\components\\chatbot.py:228: UserWarning: The `style` method is deprecated. Please set these arguments in the constructor instead.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\gradio\\blocks.py:922: UserWarning: api_name predict already exists, using predict_1\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7895\n",
      "Running on public URL: https://cd9145119419eca815.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://cd9145119419eca815.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "source_language = \"English\"  # Default language\n",
    "target_language = \"Greek\" if source_language == \"English\" else \"English\"\n",
    "translator = Translation(source_language, target_language)\n",
    "transcriber = Transcription(\"Greek\", \"English\")\n",
    "document_translator = DocumentTranslation(\"Greek\", \"English\")\n",
    "def update_language(widget, state):\n",
    "    global source_language, target_language, translator\n",
    "    source_language = widget\n",
    "    target_language = \"Greek\" if source_language == \"English\" else \"English\"\n",
    "    translator = Translation(source_language, target_language)\n",
    "    return widget\n",
    "\n",
    "def main():\n",
    "       \n",
    "    # Translate tab\n",
    "    with gr.Blocks() as chatbot_demo:\n",
    "        \n",
    "        # Create a state to hold some global variable    \n",
    "        source_language_state = gr.State(False)\n",
    "        source_language_widget = gr.Radio([\"English\", \"Greek\"], label=\"Source Language\",value=\"English\")\n",
    "        source_language_widget.change(update_language, inputs=[source_language_widget, source_language_state], outputs=[source_language_state])\n",
    "        \n",
    "    \n",
    "        with gr.Row():  # Define a Row\n",
    "            source_language_widget  # Add your widget within the Row\n",
    "\n",
    "        with gr.Row():  # Define another Row\n",
    "            with gr.Column():\n",
    "                chatbot = gr.Chatbot([], elem_id=\"Translation bot\", label = 'Translation bot').style(height=250)\n",
    "                msg = gr.Textbox()\n",
    "                clear = gr.Button(\"Clear\")\n",
    "\n",
    "                def respond(message, chat_history):\n",
    "\n",
    "                    bot_message, key_words = translator.translate(message)  # Use your chatbot_completition function here\n",
    "                    chat_history.append((message, bot_message))\n",
    "                    return \"\", chat_history, key_words\n",
    "\n",
    "                msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "                clear.click(lambda: None, None, chatbot, queue=False)\n",
    "        \n",
    "                with gr.Accordion(\"Greek examples\", open=False):\n",
    "                    gr.Examples(\n",
    "                        examples=[\"Είναι μια όμορφη ηλιόλουστη μέρα στην παραλία.\",\n",
    "                                    \"Αυτός είναι ο καλύτερος φίλος μου\",\n",
    "                                    \"Το παιδί έχει πολλά παιχνίδια\"],\n",
    "                        inputs=msg\n",
    "                    )\n",
    "            \n",
    "            with gr.Column():\n",
    "                key_words_textbox = gr.Textbox(label='Vocab',interactive= False)  # Define a textbox to show the keywords\n",
    "                msg.submit(respond, [msg, chatbot], [msg, chatbot, key_words_textbox]) \n",
    "                \n",
    "                    \n",
    "    # with gr.Row():  # Define a Row\n",
    "    #     source_language_widget  # Add your widget within the Row\n",
    "\n",
    "    # audio_input = gr.inputs.Audio(source=\"upload\", type=\"filepath\")\n",
    "    audio_input_microphone = gr.Microphone(source=\"microphone\", type=\"filepath\")\n",
    "    transcribed_text = gr.Textbox(label='Transcription',interactive= False)\n",
    "    translated_text = gr.Textbox(label='Translation',interactive= False)\n",
    "    vocab = gr.Textbox(label='Vocab',interactive= False)\n",
    "    # with gr.Row():  # Define another Row\n",
    "    #     audio_input\n",
    "    #     audio_input_microphone\n",
    "\n",
    "    transcription_interface = gr.Interface(\n",
    "        fn= transcriber.transcribe,\n",
    "        inputs= audio_input_microphone,\n",
    "        outputs=[transcribed_text, translated_text,vocab],\n",
    "        title=\"Audio Transcription\",\n",
    "        description=\"Record audio using the microphone, Greek to English only\",\n",
    "        live=True\n",
    "    )\n",
    "\n",
    "    translated_doc = gr.Textbox(label='Translated Document',interactive= False)\n",
    "    translated_doc_vocab = gr.Textbox(label='Vocab',interactive= False)\n",
    "\n",
    "    document_translation_interface = gr.Interface(\n",
    "        fn = document_translator.translate_document,\n",
    "        inputs= gr.File(label=\"Document\", type=\"file\"),\n",
    "        outputs= [translated_doc, translated_doc_vocab],\n",
    "        title=\"Document Translation\",\n",
    "        description=\"Translate a document from Greek to English\",\n",
    "        live=True\n",
    "    )\n",
    "    \n",
    "\n",
    "    # chatbot_demo.launch(share=True)\n",
    "    tabbed_interface = gr.TabbedInterface([chatbot_demo,transcription_interface, document_translation_interface], [\"Translate\", \"Transcribe\", \"Document Translation\"])\n",
    "\n",
    "    tabbed_interface.launch(share=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caching examples at: 'C:\\Users\\Jordan Moshcovitis\\Desktop\\Coding\\Chat_bots\\greek_translation_transcribe\\gradio_cached_examples\\535'\n",
      "Running on local URL:  http://127.0.0.1:7893\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7893/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def transcribe(audio_file):\n",
    "    transcription, translation = transcriber.transcribe(audio_file)\n",
    "    \n",
    "    return transcription, translation\n",
    "    \n",
    "    \n",
    "with gr.Blocks() as demo:\n",
    "\n",
    "\n",
    "    audio_input_microphone = gr.Microphone(source=\"microphone\", type=\"filepath\")\n",
    "    transcribed_text = gr.Textbox(label='Transcription',interactive= False)\n",
    "    translated_text = gr.Textbox(label='Translation',interactive= False)\n",
    "    vocab = gr.Textbox(label='Vocab',interactive= False)\n",
    "    \n",
    "    btn = gr.Button(value=\"Submit\")\n",
    "    btn.click(transcribe, inputs=audio_input_microphone, outputs=[transcribed_text,translated_text, vocab])\n",
    "    gr.Markdown(\"Example\")\n",
    "    gr.Examples(\n",
    "        examples=[\"greek1.mp3\"],\n",
    "        inputs= gr.Audio(source=\"upload\", type=\"filepath\"),\n",
    "        outputs=[transcribed_text,translated_text],\n",
    "        fn=transcribe,\n",
    "        cache_examples=True,\n",
    "    )\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradio test code\n",
    "# structure of the app\n",
    "# translate tab translalte and vocab check to select language\n",
    "\n",
    "source_language = \"English\"  # Default language\n",
    "target_language = \"Greek\" if source_language == \"English\" else \"English\"\n",
    "translator = Translation(source_language, target_language)\n",
    "\n",
    "def update_language(widget, state):\n",
    "    global source_language, target_language, translator\n",
    "    source_language = widget\n",
    "    target_language = \"Greek\" if source_language == \"English\" else \"English\"\n",
    "    translator = Translation(source_language, target_language)\n",
    "    return widget\n",
    "\n",
    "def main():\n",
    "       \n",
    "    # Translate tab\n",
    "    with gr.Blocks() as chatbot_demo:\n",
    "        # Create a state to hold some global variable    \n",
    "        source_language_state = gr.State(False)\n",
    "        source_language_widget = gr.Radio([\"English\", \"Greek\"], label=\"Source Language\",value=\"English\")\n",
    "        source_language_widget.change(update_language, inputs=[source_language_widget, source_language_state], outputs=[source_language_state])\n",
    "        \n",
    " \n",
    "        with gr.Row():  # Define a Row\n",
    "            source_language_widget  # Add your widget within the Row\n",
    "\n",
    "        with gr.Row():  # Define another Row\n",
    "            with gr.Column():\n",
    "                chatbot = gr.Chatbot([], elem_id=\"Translation bot\", label = 'Translation bot').style(height=250)\n",
    "                msg = gr.Textbox()\n",
    "                clear = gr.Button(\"Clear\")\n",
    "\n",
    "                def respond(message, chat_history):\n",
    "\n",
    "                    bot_message, key_words = translator.translate(message)  # Use your chatbot_completition function here\n",
    "                    chat_history.append((message, bot_message))\n",
    "                    return \"\", chat_history, key_words\n",
    "\n",
    "                msg.submit(respond, [msg, chatbot], [msg, chatbot])\n",
    "                clear.click(lambda: None, None, chatbot, queue=False)\n",
    "        \n",
    "                with gr.Accordion(\"Greek examples\", open=False):\n",
    "                    gr.Examples(\n",
    "                        examples=[\"Είναι μια όμορφη ηλιόλουστη μέρα στην παραλία.\",\n",
    "                                    \"Αυτός είναι ο καλύτερος φίλος μου\",\n",
    "                                    \"Το παιδί έχει πολλά παιχνίδια\"],\n",
    "                        inputs=msg\n",
    "                    )\n",
    "            \n",
    "            with gr.Column():\n",
    "                key_words_textbox = gr.Textbox(label='Vocab',interactive= False)  # Define a textbox to show the keywords\n",
    "                msg.submit(respond, [msg, chatbot], [msg, chatbot, key_words_textbox]) \n",
    "    \n",
    "    with gr.Blocks() as transcriber:\n",
    "        # Create a state to hold some global variable    \n",
    "        source_language_state = gr.State(False)\n",
    "        source_language_widget = gr.Radio([\"English\", \"Greek\"], label=\"Source Language\",value=\"Greek\")\n",
    "        source_language_widget.change(update_language, inputs=[source_language_widget, source_language_state], outputs=[source_language_state])\n",
    "        \n",
    "        with gr.Row():  # Define a Row\n",
    "            source_language_widget  # Add your widget within the Row\n",
    "\n",
    "        audio_input = gr.inputs.Audio(source=\"upload\", type=\"filepath\")\n",
    "        audio_input_microphone = gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
    "        transcribed_text = gr.outputs.Textbox()\n",
    "        translated_text = gr.outputs.Textbox()\n",
    "    \n",
    "    # # Transcription tab\n",
    "    # # set language pair with checkboxes\n",
    "    # source_language = gr.inputs.CheckboxGroup([\"English\", \"Greek\"], label=\"Source Language\")\n",
    "    # target_language = \"Greek\" if source_language == \"English\" else \"English\"\n",
    "    \n",
    "\n",
    "    # # create audio input for microphone \n",
    "    # audio_input = gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
    "    \n",
    "    # output_text = gr.outputs.Textbox()\n",
    "    \n",
    "    # transcription_interface = gr.Interface(\n",
    "    #     fn= transcribe_audio,\n",
    "    #     inputs=audio_input,\n",
    "    #     outputs=output_text,\n",
    "    #     title=\"Audio Transcription\",\n",
    "    #     description=\"Upload an audio file or record audio using the microphone, and hit the 'Submit' button.\",\n",
    "    #     live=True\n",
    "    # )\n",
    "    \n",
    "    tabbed_interface = gr.TabbedInterface([transcription_interface, chatbot_demo, chatbot_demo2], [\"Transcription\", \"Chatbot transcription\", \"Chatbot translate\"])\n",
    "\n",
    "    tabbed_interface.launch(share=True)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Γεια σου γιαγιά! Τι κάνεις? Καλός το παλικάρι μου! Μόλις τώρα έφτιαξα το αγαπημένο σου φαγητό, τα κουπέπια! Τι τυχερός που είμαι! Πώς τα κάνεις γιαγιά? Πρώτα απ' όλα, χρειάζεσαι αμπελόφυλλα. Όταν ήμουν μικρή, η μητέρα μου μάζευε τα αμπελόφυλλα από την κλιματαριά μας. Τότε όλα τα σπίτια είχαν κλιματαριές, ενώ τώρα αγοράζουν τα φύλλα από την αγορά. Τα περισσότερα υλικά που χρησιμοποιούσαμε παλιά στο μαγείρεμα\"\n",
      "\"Hello grandmother! How are you? Here's my good lad! I just made your favorite dish, the stuffed vine leaves! How lucky I am! How do you do it, grandmother? First of all, you need vine leaves. When I was young, my mother used to collect vine leaves from our vineyard. Back then, all houses had vineyards, while now they buy the leaves from the market. Most of the ingredients we used to use in our cooking were gathered this way.\"\n"
     ]
    }
   ],
   "source": [
    "transcriber = Transcription(\"Greek\", \"English\")\n",
    "\n",
    "audio_path = \"greek1.mp3\"\n",
    "\n",
    "# audio = AudioSegment.from_mp3(audio_path)\n",
    "\n",
    "proofread, translation = transcriber.transcribe(audio_path)\n",
    "print(proofread)\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transcription:\n",
    "    def __init__(self, source_language, target_language):\n",
    "        self.source_language = source_language\n",
    "        self.target_language = target_language\n",
    "        self.model = whisper.load_model(\"large\")\n",
    "        self.translate = Translation(source_language, target_language)\n",
    "\n",
    "    def transcribe(self, audio_file):\n",
    "        '''Transcribes the audio file and proofreads the transcription'''\n",
    "\n",
    "        ### Size (in bytes) = (Sample Rate) * (Bit Depth/8) * (Number of Channels) * (Duration in seconds)\n",
    "        ### Size = 44,100 * (16/8) * 1 * 60 = 5,292,000 bytes, which is approximately 5 MB.\n",
    "\n",
    "        # Calculate the size of the audio file\n",
    "        audio_file_size = os.path.getsize(audio_file)\n",
    "        audio_length = audio_file_size / ( 44100 * (16/8) * 1 )\n",
    "        logger.info(f\"Audio file size: {audio_file_size} bytes and {audio_length} seconds\")\n",
    "\n",
    "        # Transcribe the audio\n",
    "        logger.info(\"Starting transcription...\")\n",
    "        transcription = self.transcribe_audio(audio_file)\n",
    "        logger.info(f\"Transcription completed: {transcription}\")\n",
    "\n",
    "        # Proofread the transcription\n",
    "        logger.info(\"Proofreading transcription...\")\n",
    "        proofread_transcription = self.proofread_transcription(transcription)\n",
    "        logger.info(f\"Proofread transcription: {proofread_transcription}\")\n",
    "\n",
    "        # Translate the transcription\n",
    "        # translation,key_words = self.translate.translate(proofread_transcription)\n",
    "        \n",
    "        return proofread_transcription, \n",
    "    def transcribe_audio(self, audio_path):\n",
    "        '''Transcribes an audio file using the whisper model'''\n",
    "        \n",
    "        # Check if file size is less than 25 MB\n",
    "        file_size = os.path.getsize(audio_path) / (1024 * 1024) # size in MB\n",
    "        if file_size > 25:\n",
    "            raise ValueError(f\"The file size is {file_size:.2f} MB which exceeds the 25 MB limit.\")\n",
    "\n",
    "        # Check if file extension is supported\n",
    "        supported_file_types = ['mp3', 'mp4', 'mpeg', 'mpga', 'm4a', 'wav', 'webm']\n",
    "        file_extension = os.path.splitext(audio_path)[1][1:]\n",
    "        if file_extension not in supported_file_types:\n",
    "            raise ValueError(f\"The file type '{file_extension}' is not supported. Please use one of the following: {', '.join(supported_file_types)}.\")\n",
    "\n",
    "        # If checks pass, transcribe the audio\n",
    "        audio_file = open(audio_path, \"rb\")\n",
    "        transcript = openai.Audio.transcribe(\"whisper-1\", audio_file)\n",
    "\n",
    "        # Always close the file you opened\n",
    "        audio_file.close()\n",
    "\n",
    "        return transcript\n",
    "        \n",
    "        # result = self.model.transcribe(audio_file)        \n",
    "        # return result[\"text\"]\n",
    "\n",
    "    def proofread_transcription(self, transcription):\n",
    "        '''Improves the transcription quality using GPT-4'''\n",
    "        \n",
    "        SYSTEM = \"\"\"You are an expert {self.source_langauge} transcription agent. In particular, an advanced language model trained to proofread and correct text based on grammar, syntax, and coherence in context. Your role is to carefully examine the given text in {self.source_langauge}, identify semantic errors resulting from transcription, and then correct these errors. Use your knowledge of {self.source_language} language and syntax to ensure the accuracy and coherence of the transcriptions. Your task is crucial for the quality and usefulness of the transcriptions. You will be given {self.source_langauge} text that has been transcribed but may contain errors. Your job is to fix these errors to the best of your ability. Respond using markdown.\n",
    "        \n",
    "        You will work through proofreading and correcting the transcription in the following way step by step:\n",
    "        \n",
    "        Identify the context: [context]\n",
    "        Identify key words: [key words]\n",
    "        Correct the transcription: [transcription]\n",
    "        \n",
    "        You will not add any additional detail to the transcription. You will only correct the transcription. You will only return the transcription. You will not return the context or key words.\n",
    "        \n",
    "        Write the transcription here:\n",
    "               \n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        PROMPT = f\"Please proofread and correct this transcription: \\\"{transcription}\\\"\"\n",
    "        proofread_transcription = chatbot_completition(SYSTEM, PROMPT)\n",
    "        return proofread_transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"Let\\'s get into the plan\\'s details. There are several areas I wanted to discuss. Initially, we\\'ll examine what I\\'m sending you, starting with the client profile that contains a link to your plan and a check-in sheet. The check-in sheet is for facilitating the process of checking in – its main aim is providing me with all the information I need. Some clients are diligent enough and do not require the check-in sheet, but often, I recommend its use. I pay keen attention to aspects such as blood pressure, blood glucose, sleep, and your adherence to the plan. Your mental response to the protocol is also paramount.\\n\\nYour plan profile contains the plan and the check-in sheet. The client plan details your objectives: nootropic aid, improving hormone profile, and libido; reducing refractory period, creating safe muscle gain protocols, and addressing existing issues like erectile dysfunction, mild depression, and hypogonadism. You didn\\'t request dietary help, but if necessary, I can provide a suitable meal plan. Equally, I can include a workout scheme if desired.\\n\\nMoving on to the nootropic program, the initial phase will focus on upregulating BDNF, fixing dopamine levels, and eliminating neuroinflammation. For any sleep-related problems, please inform me. Apart from optimising sleep, start mornings with cold showers and sunlight exposure. Develop good morning and night habits, such as pre-bed meditation and avoiding blue light exposure. Use applications like \\'Luminosky\\' to \\'warm up\\' your brain in the morning. Maintain a low-stress lifestyle, good diet, and frequent use of a sauna. Additionally, practices like yoga and meditation can be beneficial. In the first two weeks, I recommend a dopamine fast, cutting out high dopamine activities. I strongly suspect your Modafinil use led to dopamine downregulation.\\n\\nRegarding hormones, I think some indicators suggest your hormones could be limiting you. Hence, I propose a course of 9-me-BC, 10 milligrams, taken in the morning during the two-week dopamine fast. The next step would involve CEMAX or Cerebrolysin, though CEMAX\\'s dosage would depend on the source. Additionally, let\\'s incorporate Omega Via, curcumin, RLA, the Alpha-GPC that you already have, and Hooperzine A initially, eventually transitioning to Donepezil. I recommend a gram of Tyrosine, Phenylpiracetam as you\\'ve already been using, and Uridine.\\n\\nAs we progress, we\\'ll adjust the regimen, possibly introducing NSI-189. I need to confirm if Swiss chems ship to your location.\\n\\nFor the Performance-Enhancing Drug (PED) plan, I strongly recommend Testosterone Replacement Therapy (TRT), though a more natural approach is an option. Your testosterone stack is already robust, and I\\'ve added icing the testicles, Cystange, Maca, Shilajit, and injectable Carnitine. Carnitine has the added benefit of upregulating the sensitivity of your androgen receptors, making your testosterone more effective. We can also discuss incorporating Cystange, Maca, and Shilajit into your supplement stack for libido boosting.\\n\\nBased on your blood work, your growth and IGF appear significantly low, which we should also look into addressing directly.\\n\\nAlternatively, another recommendation would be starting with testosterone at an antidote of 150 mins a week or HCG at 500 IU twice per week. I think these paths would be cheaper, healthier, and simpler than relying on natural herbs exclusively.\\n\\nFurther, supplements such as 5-HTP should be taken with caution, given it\\'s less selective than SSRIs and excessive serotonin can negatively impact the heart. I also suggest adding in glycine before bed, glutamine, berberine, and omega BF.\\n\\nIn our next stages, as we understand your response better, we can expand our approach and develop more effective strategies. I\\'d also like to include SR 9009 in your nootropic protocol for its beneficial effects.\\n\\nLastly, don\\'t hesitate to reach out if you need help with diet or training. We\\'re establishing a strong coach-client relationship here, so regular check-ins and open communication is essential. This plan is subject to changes as we move along. I hope this information is useful, and I look forward to our continued work together.\"',)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "transcriber = Transcription(\"English\", \"English\")\n",
    "\n",
    "# audio_path = \"greek1.mp3\"\n",
    "audio_path = \"what1.mp3\"\n",
    "# audio = AudioSegment.from_mp3(audio_path)\n",
    "\n",
    "proofread = transcriber.transcribe(audio_path)\n",
    "print(proofread)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"So, I would say, for HCG, what I would model would be that I really would prefer to use testosterone at a TRT dose and have HCG in the background to guarantee that adequate neurosteroid cascade kind of signaling. I\\'d introduce it and withdraw it probably two months on, two months off, just to minimize the risk of desensitization, even though it\\'s not explicitly clear in the literature. Also, I believe HCG is immensely valuable for men on TRT because it helps to maintain fertility and to keep neurosteroids active, which are important. When you inject testosterone versus when your body produces it via the LH or FSH pulse, it\\'s completely different because when you inject it, you\\'re bypassing a lot of the natural processes. So, yes, it\\'s possible. That\\'s why I prefer a two-month on and one-month off approach. We can certainly discuss more about this too. If you\\'d like, we can arrange another call, but I\\'m going to send the plan right now.\"',)\n"
     ]
    }
   ],
   "source": [
    "audio_path = \"what2.mp3\"\n",
    "# audio = AudioSegment.from_mp3(audio_path)\n",
    "\n",
    "proofread = transcriber.transcribe(audio_path)\n",
    "print(proofread)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
