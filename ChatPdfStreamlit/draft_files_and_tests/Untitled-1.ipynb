{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFDirectoryLoader(\"docs/\")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "texts = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "persist_directory = 'db'\n",
    "## here we are using OpenAI embeddings but in future we will swap out to local embeddings\n",
    "embedding = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(documents=texts, \n",
    "                                 embedding=embedding,\n",
    "                                 persist_directory=persist_directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persiste the db to disk\n",
    "vectordb.persist()\n",
    "vectordb = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can load the persisted database from disk, and use it as normal. \n",
    "vectordb = Chroma(persist_directory=persist_directory, \n",
    "                  embedding_function=embedding)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test vector db with a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='metres above ground level.\\nThis exemption does not apply to costeaning and bulk sampling activities.\\nNative vegetation that is to be removed, destroyed or lopped to the minimum extent\\nnecessary by, or on behalf of, a licenced surveyor (within the meaning of section 3 of\\ntheSurveying Act 2004 ) using hand-held tools to establish a sightline for the\\nmeasurement of land.Surveying\\nNative vegetation that is to be removed, destroyed or lopped by a person acting under,\\nand in accordance with:Traditional\\nowners\\nPage690of1122NILLUMBIK PLANNING SCHEME', metadata={'source': 'docs\\\\Nillumbik PS All Ordinance 2.pdf', 'page': 689}),\n",
       " Document(page_content='Ifnodevelopmentofthelothasbeenapprovedunderthisscheme,containabuildingenvelope\\nandbeabletocontainarectanglemeasuring10metresby15metres,or9metresby15metres\\nifaboundarywallisnominatedaspartofthebuildingenvelope.\\nIflotsofbetween300squaremetresand500squaremetresareproposedtocontaindwellingsthat\\narebuilttotheboundary,thelongaxisofthelotsshouldbewithin30degreeseastand20degrees\\nwestofnorthunlesstherearesignificantphysicalconstraintsthatmakethisdifficulttoachieve.\\nLotsgreaterthan500squaremetresshouldbeabletocontainarectanglemeasuring10metresby\\n15metres,andmaycontainabuildingenvelope.\\nAbuildingenvelopemayspecifyorincorporateanyrelevantsitinganddesignrequirement.Any\\nrequirementshouldmeettherelevantstandardsofClause54,unless:\\nTheobjectivesoftherelevantstandardsaremet,and\\nThebuildingenvelopeisshownasarestrictiononaplanofsubdivisionregisteredunderthe\\nSubdivision Act 1988 ,orisspecifiedasacovenantinanagreementunderSection173ofthe\\nAct.', metadata={'source': 'docs\\\\Nillumbik PS All Ordinance 2.pdf', 'page': 911}),\n",
       " Document(page_content='oftheActifthethresholddistanceisnottobemetornothresholddistanceisspecified.\\nTable to Clause 53.10-1\\nThreshold distance\\n(metres)Type of use or activity (purpose)\\nBasic metal products\\nIron or steel production:\\n500\\n up to 1,000,000 tonnes per year\\n1,000\\n exceeding 1,000,000 tonnes per year\\nNon-ferrous metal production:\\n100\\n up to 100 tonnes per year\\n300\\n between 100 and 2,000 tonnes per year\\n500\\n exceeding 2,000 tonnes per year\\n2,000\\n aluminium by electrolysis\\nChemical, petroleum and coal products\\n1,000 Ammunition, explosives and fireworks production\\n1,000 Biocides production and storage\\n300 Briquette production\\n300 Chemical product manufacture other than listed within this group\\nPage793of1122NILLUMBIK PLANNING SCHEME', metadata={'source': 'docs\\\\Nillumbik PS All Ordinance 2.pdf', 'page': 792}),\n",
       " Document(page_content='to6.9metres,plus1metreforeverymetreofheightover6.9metres.Diagram2detailsthestandard.\\nSunblinds,verandahs,porches,eaves,fascias,gutters,masonrychimneys,flues,pipes,domestic\\nfuelorwatertanks,andheatingorcoolingequipmentorotherservicesmayencroachnotmore\\nthan0.5metresintothesetbacksofthisstandard.\\nLandingshavinganareaofnotmorethan2squaremetresandlessthan1metrehigh,stairways,\\nramps,pergolas,shadesailsandcarportsmayencroachintothesetbacksofthisstandard.\\nPage830of1122NILLUMBIK PLANNING SCHEME', metadata={'source': 'docs\\\\Nillumbik PS All Ordinance 2.pdf', 'page': 829})]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectordb.similarity_search(\"waht is metrology?\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct conversational retrieval chain\n",
    "\n",
    "Requirements:\n",
    "- chat model\n",
    "- chat memory\n",
    "- return sources\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).\n"
     ]
    }
   ],
   "source": [
    "CONDENSE_PROMPT = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "QA_PROMPT = \"\"\"You will act as an AI Assistant that I am having a conversation with. You have the expertise of an expert physics professor that specialises in advanced mathematical physics and dynamical mechanics. You will provide answers and guidance from your extensive knowledge, and will always provide relevant theorems when requested. Additionally, you will ask follow-up questions to clarify the last response and provide more accurate and personalized answers. If the answer is not included in your knowledge base, you will say 'Hmm, I am not sure.' and stop after that. Your goal is to provide the best possible guidance and support to help me with my queries and problems. You think things through step by step every time and show your working. You break down problems into simple steps before solving and always double check your answers. \n",
    "\n",
    "{summaries}\n",
    "\n",
    "Question: {question}\n",
    "Helpful answer in markdown or latex where equations are included:\"\"\"\n",
    "\n",
    "# Create PromptTemplate instances\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"], \n",
    "    template=CONDENSE_PROMPT\n",
    ")\n",
    "\n",
    "QA_PROMPT_TEMPLATE = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"], \n",
    "    template=QA_PROMPT\n",
    ")\n",
    "\n",
    "\n",
    "gpt3 = ChatOpenAI(temperature=0, model_name = 'gpt-3.5-turbo')\n",
    "gpt4 = ChatOpenAI(temperature=0, model_name = 'gpt-4')\n",
    "question_generator = LLMChain(llm=gpt3, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_with_sources_chain(gpt4, chain_type=\"stuff\", prompt=QA_PROMPT_TEMPLATE)\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents = True\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "query = \"What are important equationas in dyanmical metrology??\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What are important equationas in dyanmical metrology??',\n",
       " 'chat_history': [],\n",
       " 'answer': 'In dynamical meteorology, some of the important equations are:\\n\\n1. **Mass Continuity Equation**: This equation describes the conservation of mass in a fluid system. It is given by:\\n\\n   $$\\\\frac{\\\\partial \\\\rho}{\\\\partial t} + \\\\nabla \\\\cdot (\\\\rho \\\\mathbf{u}) = 0$$\\n\\n   where $\\\\rho$ is the density of the fluid, $t$ is time, and $\\\\mathbf{u}$ is the velocity vector.\\n\\n2. **Momentum Equation**: This equation describes the conservation of momentum in a fluid system. In a rotating frame of reference, it is given by:\\n\\n   $$\\\\rho \\\\frac{D\\\\mathbf{u}}{Dt} = -\\\\nabla p + \\\\rho \\\\mathbf{g} - 2\\\\rho \\\\mathbf{u} \\\\times \\\\mathbf{\\\\Omega} + \\\\rho \\\\mathbf{F}_{friction}$$\\n\\n   where $D/Dt$ is the material derivative, $p$ is pressure, $\\\\mathbf{g}$ is the gravitational acceleration vector, $\\\\mathbf{\\\\Omega}$ is the angular velocity vector of the Earth, and $\\\\mathbf{F}_{friction}$ is the frictional force per unit mass.\\n\\n3. **Thermodynamic Equation**: This equation describes the conservation of energy in a fluid system. For an ideal gas, it can be written as:\\n\\n   $$\\\\frac{D\\\\theta}{Dt} = 0$$\\n\\n   where $\\\\theta$ is the potential temperature.\\n\\n4. **Equation of State**: This equation relates the pressure, density, and temperature of a fluid. For an ideal gas, it is given by:\\n\\n   $$p = \\\\rho R_d T$$\\n\\n   where $R_d$ is the specific gas constant for dry air and $T$ is the temperature.\\n\\n5. **Hydrostatic Balance**: This equation describes the balance between the vertical pressure gradient force and the gravitational force in the atmosphere. It is given by:\\n\\n   $$\\\\frac{\\\\partial p}{\\\\partial z} = -\\\\rho g$$\\n\\n   where $z$ is the vertical coordinate.\\n\\nThese equations, along with appropriate boundary conditions and initial conditions, form the basis for studying the dynamics of the atmosphere in meteorology.',\n",
       " 'source_documents': [Document(page_content='that the scale of motion is much larger than the deformation scale then the other terms in the ther-\\nmodynamic equation will become equally important. Thus, we suppose that 𝐿2\\n𝑑≪ 𝐿2or, more\\nformally, that𝐿2=𝒪(Ro−1)𝐿2\\n𝑑, and then all the terms in the thermodynamic equation are retained.\\nA closed set of equations is then given by ( 5.47) and the thermodynamic equation ( 5.32).\\nDimensional equations\\nRestoringthedimensions, droppingtheasymptotic subscripts, andallowingfor thepossibility ofa\\nsourceterm, denotedby 𝑆[𝑏′], inthethermodynamicequation, the planetary-geostrophic equations\\nof motion are:\\nD𝑏′\\nD𝑡+𝑤𝑁2=𝑆[𝑏′],\\n𝒇×𝒖=−∇𝜙′,𝜕𝜙′\\n𝜕𝑧=𝑏′, ∇⋅𝒗=0.(4.49)\\nThe thermodynamic equation may also be written simply as\\nD𝑏\\nD𝑡=̇𝑏, (4.50)\\nwhere𝑏now represents the total stratification. The relevant pressure, 𝜙, is then the pressure that is\\ninhydrostaticbalancewith 𝑏, sothatgeostrophicandhydrostaticbalancearemostusefullywritten\\nas\\n𝒇×𝒖=−∇𝜙,𝜕𝜙\\n𝜕𝑧=𝑏. (4.51a,b)\\nPotential vorticity', metadata={'source': 'docs\\\\Atmospheric and Oceanic Fluid Dynamics by G. K. Vallis.pdf', 'page': 57}),\n",
       "  Document(page_content='C\\nontents\\nPreface xiii\\nNotation xvii\\nPART I FUNDAMENTALS OF GEOPHYSICAL FLUID DYNAMICS 1\\n1 Equations of Motion 3\\n1.1 Time Derivatives for Fluids 3\\n1.2 The Mass Continuity Equation 7\\n1.3 The Momentum Equation 11\\n1.4 The Equation of State 13\\n1.5 Thermodynamic Relations 14\\n1.6 Thermodynamic Equations for Fluids 21\\n1.7 Thermodynamics of Seawater 30\\n1.8 Sound Waves 40\\n1.9 Compressible and Incompressible Flow 41\\n1.10 The Energy Budget 42\\n1.11 An Introduction to nondimensionalization and Scaling 46\\nAppendix A: Thermodynamics of an Ideal gas from the Gibbs function 47\\nAppendix B: The First Law of Thermodynamics for Fluids 49\\n2 Eﬀects of Rotation and Stratiﬁcation 55\\n2.1 Equations of Motion in a Rotating Frame 55\\n2.2 Equations of Motion in Spherical Coordinates 59\\n2.3 Cartesian Approximations: The Tangent Plane 69\\n2.4 The Boussinesq Approximation 70\\n2.5 The Anelastic Approximation 75\\n2.6 Pressure and other Vertical Coordinates 79\\n2.7 Scaling for Hydrostatic Balance 83', metadata={'source': 'docs\\\\Atmospheric and Oceanic Fluid Dynamics by G. K. Vallis.pdf', 'page': 7}),\n",
       "  Document(page_content='on the thermodynamic energy equation. Both methods are usually applied using\\nthe isobaric coordinate system so that !.p/is inferred rather than w.z/. These\\ntwo measures of vertical motion can be related to each other with the aid of the\\nhydrostatic approximation.\\nExpanding Dp=Dtin the ( x,y,z) coordinate system yields\\n!\\x11Dp\\nDtD@p\\n@tCV\\x01rpCw\\x12@p\\n@z\\x13\\n(3.36)\\nNow, for synoptic-scale motions, the horizontal velocity is geostrophic to a\\nﬁrst approximation. Therefore, we can write VDVgCVa, where Vais the\\nageostrophic wind andjVaj\\x1cj Vgj. However, VgD.\\x1af/\\x001k\\x02rp, so that\\nVg\\x01rpD0. Using this result plus the hydrostatic approximation, (3.36) may\\nbe rewritten as\\n!D@p\\n@tCVa\\x01rp\\x00g\\x1aw (3.37)\\nComparing the magnitudes of the three terms on the right in (3.37), we ﬁnd that\\nfor synoptic-scale motions\\n@p=@t\\x1810 hPa d\\x001\\nVa\\x01rp\\x18\\x10\\n1 m s\\x001\\x11\\x10\\n1 Pa km\\x001\\x11\\n\\x181 hPa d\\x001\\ng\\x1aw\\x18100 hPa d\\x001\\nThus, it is quite a good approximation to let\\n!D\\x00\\x1agw (3.38)\\n3.5.1 The Kinematic Method', metadata={'source': 'docs\\\\An Introduction to Dynamic Meteorology by J.R. Holton.pdf', 'page': 89}),\n",
       "  Document(page_content='The presence of nonlinear advection processes is one reason that dynamic\\nmeteorology is an interesting and challenging subject.\\n2.4 SCALE ANALYSIS OF THE EQUATIONS OF MOTION\\nSection 1.6 discussed the basic notion of scaling the equations of motion in order\\nto determine whether some terms in the equations are negligible for motions of\\nmeteorological concern. Elimination of terms on scaling considerations have\\nthe advantage of simplifying the mathematics; as shown in later chapters, the\\nelimination of small terms in some cases has the very important property of\\ncompletely eliminating or ﬁltering an unwanted type of motion. The complete\\nequations of motion—(2.19), (2.20), and (2.21)—describe all types and scales\\nof atmospheric motions. Sound waves, for example, are a perfectly valid class\\nof solutions to these equations. However, sound waves are of negligible impor-\\ntance in dynamical meteorology. Therefore, it will be a distinct advantage if,', metadata={'source': 'docs\\\\An Introduction to Dynamic Meteorology by J.R. Holton.pdf', 'page': 45})]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CONDENSE_PROMPT = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "QA_PROMPT = \"\"\"You will act as an AI Assistant that I am having a conversation with. You have the expertise of an expert physics professor that specialises in advanced mathematical physics and dynamical mechanics. You will provide answers and guidance from your extensive knowledge, and will always provide relevant theorems when requested. Additionally, you will ask follow-up questions to clarify the last response and provide more accurate and personalized answers. If the answer is not included in your knowledge base, you will say 'Hmm, I am not sure.' and stop after that. Your goal is to provide the best possible guidance and support to help me with my queries and problems. You think things through step by step every time and show your working. You break down problems into simple steps before solving and always double check your answers. \n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful answer in markdown or latex where equations are included:\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "model = ChatOpenAI(temperature=0.9, model_name = 'gpt-4')\n",
    "chain = ConversationalRetrievalChain.from_llm(model,vectordb.as_retriever(), memory = memory, return_source_documents = True) \n",
    "    # {\n",
    "    #     'qaTemplate': QA_PROMPT,\n",
    "    #     'questionGeneratorTemplate': CONDENSE_PROMPT,\n",
    "    #     'returnSourceDocuments': True,  # The number of source documents returned is 4 by default\n",
    "    # },\n",
    "\n",
    "query = \"What is coriolis force?\"\n",
    "result = chain({\"question\": query})\n",
    "result['answer']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDENSE_PROMPT = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "# Create PromptTemplate instances\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"], \n",
    "    template=CONDENSE_PROMPT\n",
    ")\n",
    "# Construct a ConversationalRetrievalChain with a streaming llm for combine docs\n",
    "# and a separate, non-streaming llm for question generation\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "gpt3 = ChatOpenAI(temperature=0, model_name = 'gpt-3.5-turbo')\n",
    "gpt4 = ChatOpenAI(temperature=0, model_name = 'gpt-4')\n",
    "question_generator = LLMChain(llm=gpt3, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_with_sources_chain(gpt4, chain_type=\"stuff\")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    ")\n",
    "chat_history = []\n",
    "query = \"What is coriolis force?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "result['answer']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
    "# QA_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONDENSE_PROMPT = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "QA_PROMPT = \"\"\"You will act as an AI Assistant that I am having a conversation with. You have the expertise of an expert physics professor that specialises in advanced mathematical physics and dynamical mechanics. You will provide answers and guidance from your extensive knowledge, and will always provide relevant theorems when requested. Additionally, you will ask follow-up questions to clarify the last response and provide more accurate and personalized answers. If the answer is not included in your knowledge base, you will say 'Hmm, I am not sure.' and stop after that. Your goal is to provide the best possible guidance and support to help me with my queries and problems. You think things through step by step every time and show your working. You break down problems into simple steps before solving and always double check your answers. \n",
    "\n",
    "{summaries}\n",
    "\n",
    "Question: {question}\n",
    "Helpful answer in markdown or latex where equations are included:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "\n",
    "# Create PromptTemplate instances\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"chat_history\", \"question\"], \n",
    "    template=CONDENSE_PROMPT\n",
    ")\n",
    "\n",
    "QA_PROMPT_TEMPLATE = PromptTemplate(\n",
    "    input_variables=[\"summaries\", \"question\"], \n",
    "    template=QA_PROMPT\n",
    ")\n",
    "\n",
    "\n",
    "gpt3 = ChatOpenAI(temperature=0, model_name = 'gpt-3.5-turbo')\n",
    "gpt4 = ChatOpenAI(temperature=0, model_name = 'gpt-4')\n",
    "question_generator = LLMChain(llm=gpt3, prompt=CONDENSE_QUESTION_PROMPT)\n",
    "doc_chain = load_qa_with_sources_chain(gpt4, chain_type=\"stuff\", prompt=QA_PROMPT_TEMPLATE)\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    "    return_source_documents = True\n",
    ")\n",
    "\n",
    "chat_history = []\n",
    "query = \"What are important equationas in dyanmical metrology??\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. First, create a custom chat prompt template using the SystemMessagePromptTemplate and HumanMessagePromptTemplate classes:\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_prompt_template = \"Your custom system prompt template with {variables}\"\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(system_prompt_template)\n",
    "\n",
    "human_prompt_template = \"Your custom human prompt template with {variables}\"\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt, human_message_prompt])\n",
    "\n",
    "\n",
    "# 2. Next, create a ChatOpenAI instance and use it with your custom chat prompt template:\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "chat_model = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "question_generator = LLMChain(llm=chat_model, prompt=chat_prompt)\n",
    "\n",
    "\n",
    "# 3. Finally, use the question_generator with your custom chat prompt template in the ConversationalRetrievalChain:\n",
    "\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "doc_chain = load_qa_chain(chat_model, chain_type=\"map_reduce\")\n",
    "\n",
    "chain = ConversationalRetrievalChain(\n",
    "    retriever=vectorstore.as_retriever(),\n",
    "    question_generator=question_generator,\n",
    "    combine_docs_chain=doc_chain,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised Timeout: Request timed out: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=60).\n"
     ]
    }
   ],
   "source": [
    "from pdf_chat_bot import chat_bot_response\n",
    "chat_history = []\n",
    "query = \"What are important equationas in dyanmical metrology??\"\n",
    "chat_bot_response(query, chat_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
